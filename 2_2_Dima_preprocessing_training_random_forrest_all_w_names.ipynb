{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "# Output of this script - \n",
    "#\n",
    "#\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# BASE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "import pickle\n",
    "\n",
    "#VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "#??????????????????????? WHAT ARE YOU????????????????????????\n",
    "from scipy.stats import mode                                                        #?????????????????????????????????\n",
    "from sklearn.datasets import load_digits                                            #?????????????????????????????\n",
    "from sklearn.decomposition import PCA                                               #??????????????????????????\n",
    "from sklearn.manifold import TSNE                                                   #????????????????????????????\n",
    "from sklearn.datasets import make_classification                                    #??????????????????????????\n",
    "from scipy.special import expit                                                     #???????????????????????????\n",
    "\n",
    "\n",
    "#VOTING\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#CLASIFIERS\n",
    "from sklearn.tree import DecisionTreeClassifier                                     \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV                # search of the best params for random_forrest\n",
    "from sklearn.linear_model import SGDClassifier                                      #????????????????????????\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors                                      #????????????????????????\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC                                                         #???????????\n",
    "from sklearn.ensemble import AdaBoostClassifier                                     #?????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#REGRESSORS\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CLASTERING\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch                                               #????????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCALERS and TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# metrics and processing \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore, boxcox\n",
    "from sklearn.model_selection import cross_val_score                                 #??????????????????????????\n",
    "\n",
    "\n",
    "\n",
    "# EDA data treatment\n",
    "import missingno\n",
    "\n",
    "\n",
    "# other (mainly system libs)\n",
    "import warnings\n",
    "import sys\n",
    "from io import StringIO\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import urllib.request as req\n",
    "import zipfile\n",
    "import csv\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Constants\n",
    "\n",
    "SEED = 50\n",
    "FILE = './data/glove.6B.50d.txt'\n",
    "\n",
    "\n",
    "STOP_WORDS_FULL = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \n",
    "'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    " 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
    "'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \n",
    "'s', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "STOP_WORDS_SHORT = ['a', 'an', 'the', 'as', 'while', 'of', 'by', 'for', 'to', \n",
    "'then', 'so', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "ZERO_VECTOR = [0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0,\n",
    "                0,0,0,0,0,0,0,0,0,0\n",
    "            ]\n",
    "################################################################\n",
    "\n",
    "# Loading splits for processing\n",
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>country</th>\n",
       "      <th>launched</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>pledged</th>\n",
       "      <th>backers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeadaHose, The world's most versatile dog leash!</td>\n",
       "      <td>Design</td>\n",
       "      <td>Product Design</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2014-08-13 01:55:07</td>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>18106</td>\n",
       "      <td>14270</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Stairs</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Animation</td>\n",
       "      <td>United States</td>\n",
       "      <td>2012-06-16 23:05:26</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>3800</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Besuch des Grauens 2016</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2015-11-25 17:24:35</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>4551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taskin Kompak: The Easy Way to Pack More &amp; Mes...</td>\n",
       "      <td>Design</td>\n",
       "      <td>Product Design</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017-08-08 15:00:05</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>3000</td>\n",
       "      <td>289108</td>\n",
       "      <td>4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Face - European Tour 2015</td>\n",
       "      <td>Music</td>\n",
       "      <td>Rock</td>\n",
       "      <td>United States</td>\n",
       "      <td>2015-03-17 06:40:59</td>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>25000</td>\n",
       "      <td>32119</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265164</th>\n",
       "      <td>\"Born Again Sage\" A heavy metal musical comedy</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>United States</td>\n",
       "      <td>2011-03-09 01:11:56</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1600</td>\n",
       "      <td>1792</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265165</th>\n",
       "      <td>Unseen Waterloo- The Conflict Revisited: The Book</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Photobooks</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2014-11-03 19:56:52</td>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>23565</td>\n",
       "      <td>27448</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265166</th>\n",
       "      <td>The Legacy : Minimalist High Tops for Urban Co...</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017-09-11 15:59:21</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>30000</td>\n",
       "      <td>73998</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265167</th>\n",
       "      <td>What Would You Say To A Million People?</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016-10-31 19:47:01</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>7574</td>\n",
       "      <td>221</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265168</th>\n",
       "      <td>The Ninja Book Box</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016-09-02 08:51:16</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>616</td>\n",
       "      <td>2205</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265169 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name      category   \n",
       "0        LeadaHose, The world's most versatile dog leash!        Design  \\\n",
       "1                                              The Stairs  Film & Video   \n",
       "2                                 Besuch des Grauens 2016    Publishing   \n",
       "3       Taskin Kompak: The Easy Way to Pack More & Mes...        Design   \n",
       "4                               Face - European Tour 2015         Music   \n",
       "...                                                   ...           ...   \n",
       "265164     \"Born Again Sage\" A heavy metal musical comedy  Film & Video   \n",
       "265165  Unseen Waterloo- The Conflict Revisited: The Book   Photography   \n",
       "265166  The Legacy : Minimalist High Tops for Urban Co...       Fashion   \n",
       "265167            What Would You Say To A Million People?    Publishing   \n",
       "265168                                 The Ninja Book Box    Publishing   \n",
       "\n",
       "           subcategory         country             launched    deadline   \n",
       "0       Product Design       Australia  2014-08-13 01:55:07  2014-09-10  \\\n",
       "1            Animation   United States  2012-06-16 23:05:26  2012-07-16   \n",
       "2              Fiction         Germany  2015-11-25 17:24:35  2015-12-15   \n",
       "3       Product Design   United States  2017-08-08 15:00:05  2017-09-13   \n",
       "4                 Rock   United States  2015-03-17 06:40:59  2015-04-16   \n",
       "...                ...             ...                  ...         ...   \n",
       "265164    Film & Video   United States  2011-03-09 01:11:56  2011-04-09   \n",
       "265165      Photobooks  United Kingdom  2014-11-03 19:56:52  2014-12-08   \n",
       "265166        Footwear   United States  2017-09-11 15:59:21  2017-10-26   \n",
       "265167      Publishing  United Kingdom  2016-10-31 19:47:01  2016-11-30   \n",
       "265168      Publishing  United Kingdom  2016-09-02 08:51:16  2016-10-02   \n",
       "\n",
       "         goal  pledged  backers  \n",
       "0       18106    14270       68  \n",
       "1        3800      125        2  \n",
       "2        4551        0        0  \n",
       "3        3000   289108     4978  \n",
       "4       25000    32119      391  \n",
       "...       ...      ...      ...  \n",
       "265164   1600     1792       32  \n",
       "265165  23565    27448      189  \n",
       "265166  30000    73998      759  \n",
       "265167   7574      221        8  \n",
       "265168    616     2205       43  \n",
       "\n",
       "[265169 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_glove_library(file): #Borrowed with little modifications from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "    print('Loading GloVe library '+ file)\n",
    "    glove_model = {}\n",
    "    with open(file,'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word = line.split(' ')[0]\n",
    "            glove_model[str(word)] = np.array(line.split()[1:], dtype=np.float64)\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "def load_glove_large(file):\n",
    "    df = pd.read_csv(file, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove_model = {key: val.values for key, val in df.T.items()}\n",
    "    return glove_model\n",
    "\n",
    "def text_prep(text):\n",
    "    text=text.lower()\n",
    "    for val in list(string.whitespace)[1:]:\n",
    "        while val in text:\n",
    "            text = text.replace(val, ' ')\n",
    "    for char in \",.-=+_!?:;@#/|\\$%^&*()[]{}\":\n",
    "        while (char in text):\n",
    "            text = text.replace(char, ' ')\n",
    "    while '\"' in text:\n",
    "        text = text.replace('\"', ' ')\n",
    "    while \"'\" in text:\n",
    "        text = text.replace(\"'\", ' ')\n",
    "    while \" \"*6 in text:\n",
    "        text = text.replace(\" \"*6, ' ')\n",
    "    while \" \"*5 in text:\n",
    "        text = text.replace(\" \"*5, ' ')\n",
    "    while \" \"*4 in text:\n",
    "        text = text.replace(\" \"*4, ' ')\n",
    "    while \" \"*3 in text:\n",
    "        text = text.replace(\" \"*3, ' ')\n",
    "    while \" \"*2 in text:\n",
    "        text = text.replace(\" \"*2, ' ')\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def whole_name_vectorizer(text, model):\n",
    "    sent_vec = ZERO_VECTOR\n",
    "    numw = 0\n",
    "    for wrd in text.split():\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                try :sent_vec = model[wrd]\n",
    "                except: sent_vec = ZERO_VECTOR\n",
    "            else:\n",
    "                try: sent_vec = np.add(sent_vec, model[wrd])\n",
    "                except: sent_vec = np.add(sent_vec, ZERO_VECTOR)\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return np.asarray(sent_vec) / numw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For column transformer:\n",
    "def names_vectorizer(df:pd.DataFrame, colname, model):\n",
    "    new_col = df[colname].astype('string').str.lower()\n",
    "    new_col = new_col.apply(lambda x: text_prep(x))\n",
    "    for itr in range(new_col.shape[0]):\n",
    "        vec_mod = 0\n",
    "        new_col[itr] = whole_name_vectorizer(new_col[itr], model)\n",
    "    return pd.Series(new_col)\n",
    "\n",
    "#For pipline:\n",
    "#def names_vectorizer_pipeline(sentence):\n",
    "#    sent_vec = ZERO_VECTOR\n",
    "#    numw = 0\n",
    "#    for wrd in sentence.split():\n",
    "#        try:\n",
    "#            if numw == 0:\n",
    "#                try :sent_vec = GLOVE_LIB[wrd]\n",
    "#                except: sent_vec = ZERO_VECTOR\n",
    "#            else:\n",
    "#                try: sent_vec = np.add(sent_vec, GLOVE_LIB[wrd])\n",
    "#                except: sent_vec = np.add(sent_vec, ZERO_VECTOR)\n",
    "#            numw+=1\n",
    "#        except:\n",
    "#            pass\n",
    "#    return np.asarray(sent_vec) / numw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dol_p_back(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['backers_adj'] = df['backers'] + (0.0001)\n",
    "    df['dol_p_back'] = df['pledged']/df['backers_adj']\n",
    "    return pd.DataFrame(df['dol_p_back'])\n",
    "\n",
    "\n",
    "def log10p1_of_val(val):\n",
    "    return np.log10(val+1)\n",
    "\n",
    "# Formating dates\n",
    "def pre_processing_dates(df:pd.DataFrame , colname)-> pd.DataFrame:\n",
    "    df[colname] = pd.to_datetime(df[colname])\n",
    "    df[colname+'_day_frac'] = df[colname].dt.day/31\n",
    "    df[colname+'_month_frac'] = df[colname].dt.month/12\n",
    "    df[colname+'_year_frac'] = df[colname].dt.year/2024\n",
    "    df[colname+'_dow'] = df[colname].dt.day_name()\n",
    "    return pd.DataFrame(df[[colname+'_day_frac',colname+'_month_frac',colname+'_year_frac']].join(pd.get_dummies(df[colname+'_dow'], prefix='launched', prefix_sep='_', drop_first = False, dtype=float))   )\n",
    "\n",
    "def duration_years(df:pd.DataFrame)-> pd.DataFrame:\n",
    "    df['launched'] = pd.to_datetime(df['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['deadline'] = pd.to_datetime(df['deadline'], format='%Y-%m-%d')\n",
    "    df['duration_years'] = df['deadline'] - df['launched']\n",
    "    df['duration_years'] = df['duration_years'].dt.days.astype('int')\n",
    "    return pd.DataFrame(df['duration_years']/365)\n",
    "\n",
    "def goal_lin_norm(df:pd.DataFrame , colname)-> pd.DataFrame:\n",
    "    return pd.DataFrame(df[colname]/df[colname].max())\n",
    "\n",
    "# Just in case...\n",
    "def keep_initial(df:pd.DataFrame , columns)-> pd.DataFrame:\n",
    "    return pd.DataFrame(df[columns])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "COLUMNS_TO_KEEP = ['name']\n",
    "#name_pipeline = Pipeline(steps =  [\n",
    "#                            ('tovec', FunctionTransformer(names_vectorizer, kw_args={'colname':'name', 'model':GLOVE_LIB}, validate=False)),\n",
    "#                            ('scale', StandardScaler()),\n",
    "#                            ('pca', PCA(0.99, random_state=0)),\n",
    "#                            ('bins', KMeans(n_clusters=14, init='k-means++', max_iter=1000, n_init='auto', random_state=SEED))\n",
    "#])\n",
    "\n",
    "\n",
    "GLOVE_LIB = load_glove_large(FILE)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "                    ('ct', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['category']),\n",
    "                    ('sct', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['subcategory']),\n",
    "                    ('ctry', OneHotEncoder(drop=None, handle_unknown='infrequent_if_exist', sparse_output=False), ['country']),\n",
    "                    ('l', FunctionTransformer(pre_processing_dates, kw_args={'colname':'launched'}, validate=False), ['launched']),\n",
    "                    ('d', FunctionTransformer(pre_processing_dates, kw_args={'colname':'deadline'}, validate=False), ['deadline']),\n",
    "                    ('dpb', FunctionTransformer(calc_dol_p_back, validate=False), ['backers', 'pledged']),\n",
    "                    ('cdy', FunctionTransformer(duration_years, validate=False), ['launched', 'deadline']),\n",
    "                    ('fmaxg', FunctionTransformer(goal_lin_norm, kw_args={'colname':'goal'}, validate=False), ['goal']),\n",
    "                    ('fmaxp', FunctionTransformer(goal_lin_norm, kw_args={'colname':'pledged'}, validate=False), ['pledged']),\n",
    "                    ('fmaxb', FunctionTransformer(goal_lin_norm, kw_args={'colname':'backers'}, validate=False), ['backers']),\n",
    "#                    ('av_vec', name_pipeline, ['name'])\n",
    "#                    ('av_vec', FunctionTransformer(names_vectorizer, kw_args={'colname':'name', 'model':GLOVE_LIB}, validate=False), ['name'])\n",
    "                    ('original', FunctionTransformer(keep_initial, kw_args={'columns':COLUMNS_TO_KEEP}, validate=False), COLUMNS_TO_KEEP)\n",
    "                    ],remainder='drop').set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "X_train_transf = preprocessor.fit_transform(X_train)\n",
    "X_test_transf = preprocessor.transform(X_test)\n",
    "pickle\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a hot-plug due to inability to implement pipeline\n",
    "X_train_transf['vec_name'] = names_vectorizer(df=X_train_transf, colname='original__name', model=GLOVE_LIB)\n",
    "X_test_transf['vec_name'] = names_vectorizer(df=X_test_transf, colname='original__name', model=GLOVE_LIB)\n",
    "\n",
    "X_train_transf = X_train_transf.drop('original__name', axis=1)\n",
    "X_test_transf = X_test_transf.drop('original__name', axis=1)\n",
    "\n",
    "clasters = KMeans(n_clusters=14, init='k-means++', max_iter=1000, n_init='auto', random_state=SEED)\n",
    "\n",
    "X_train_transf['name_cluster'] = pd.Series(clasters.fit_predict(X_train_transf['vec_name'].values.tolist() ),  name='name_cluster')\n",
    "X_test_transf['name_cluster'] = pd.Series(clasters.predict(X_test_transf['vec_name'].values.tolist()),  name='name_cluster')\n",
    "\n",
    "X_train_transf = X_train_transf.drop('vec_name', axis=1)\n",
    "X_test_transf = X_test_transf.drop('vec_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   40.6s finished\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#                                           MODEL           2\n",
    "model_2 = RandomForestClassifier(n_estimators=150, random_state=SEED, n_jobs=-1, verbose = 1)\n",
    "model_2.fit(X_train_transf, y_train.values.ravel())\n",
    "##################################################################################################\n",
    "\n",
    "filename = 'models/Dima_random_forrest_all_w_namevec_bins.sav'\n",
    "pickle.dump(model_2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     39523\n",
      "           1       0.96      0.95      0.96     26770\n",
      "\n",
      "    accuracy                           0.96     66293\n",
      "   macro avg       0.96      0.96      0.96     66293\n",
      "weighted avg       0.96      0.96      0.96     66293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 150 out of 150 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiSElEQVR4nO3de3QU9f3/8dcGyQYkWRouuRSwCAgiDbYRY0BuEgnxWyoQK2oVEL74g2+gJan1RwBFsHYpXrgcQ2ot5aapqN+CguUiAUJVKBAbUdGUIBoREi5KIkGXSPb7B8c97iyXLGwy25nno2fOcWdnZz7bc/SV9/vzmVmH1+v1CgAA2EaE2QMAAACNi/AHAMBmCH8AAGyG8AcAwGYIfwAAbIbwBwDAZgh/AABshvAHAMBmCH8AAGzmCrMH8B3H4O5mDwEIO96Nm8weAhCmEhv07KHMJO/GvSE7V6iETfgDABA2HGYPoGHR9gcAwGao/AEAMHJYu/Qn/AEAMLJ29hP+AAAEsHjlz5w/AAA2Q+UPAICRtQt/wh8AgAAR1k5/2v4AANgMlT8AAEbWLvwJfwAAArDaHwAAWAmVPwAARtYu/Al/AAACWDz8afsDAGAzVP4AABhZfMEf4Q8AgJG1s5/wBwAggMUrf+b8AQCwGSp/AACMrF34E/4AAASg7Q8AAKyEyh8AACOLl8aEPwAARtbu+lv9bxsAAGBE5Q8AgJHFF/wR/gAAGFk7+2n7AwBgN4Q/AABGDkfotiDk5+crKSlJMTExiomJUWpqqtatW+d7f8CAAXI4HH7bhAkTgv56tP0BADAyqe3frl07zZkzR126dJHX69WyZct0++2361//+peuu+46SdL48eM1e/Zs32eaN28e9HUIfwAAjExa8Dd06FC/148//rjy8/O1Y8cOX/g3b95c8fHxl3Ud2v4AADQgj8ej6upqv83j8Vz0c2fOnNGLL76ompoapaam+va/8MILat26tXr06KHc3FydOnUq6DER/gAAGDlCt7ndbrlcLr/N7Xaf99LvvfeeWrRoIafTqQkTJmjVqlXq3r27JOmee+7R888/ry1btig3N1crVqzQvffeG/zX83q93qA/1QAcg7ubPQQg7Hg3bjJ7CECYSmzQszvG9ArZub559s2ASt/pdMrpdJ7z+NOnT6u8vFxVVVV65ZVX9Oc//1lFRUW+PwC+b/PmzRo0aJDKysrUqVOneo+JOX8AABrQhYL+XCIjI9W5c2dJUnJysnbt2qUFCxbo2WefDTg2JSVFkgh/AAAuWxg95Keuru68awRKSkokSQkJCUGdk/AHAMDIpBVxubm5ysjIUIcOHfTVV1+poKBAW7du1YYNG7R//34VFBTotttuU6tWrbRnzx5lZ2erX79+SkpKCuo6hD8AAGHiyJEjGjVqlA4fPiyXy6WkpCRt2LBBt956qz777DNt2rRJ8+fPV01Njdq3b6/MzEzNmDEj6OsQ/gAAGJl0n//ixYvP+1779u1VVFQUkusQ/gAAGIXRnH9D4D5/AABshsofAAAjk9r+jYXwBwDAyNrZT/gDABDA4pU/c/4AANgMlT8AAEbWLvwJfwAAjCze9aftDwCA3VD5AwBg4LB46U/4AwBgYPHsp+0PAIDdUPkDAGAQYfHSn/AHAMDA4tlP2x8AALuh8gcAwMDihT/hDwCAEbf6AQBgMxbPfub8AQCwGyp/AAAMrF75E/4AABhYfc6ftj8AADZD5Q8AgIHFC3/CHwAAI9r+AADAUqj8AQAwsHjhT/gDAGBk9ba41b8fAAAwoPIHAMDA6gv+CH8AAAwsnv2EPwAARlYPf+b8AQCwGSp/AAAMmPMHAMBmLJ79tP0BALAbKn8AAAxo+wMAYDMWz37a/gAA2A2VPwAABhYv/Kn8AQAwcjgcIduCkZ+fr6SkJMXExCgmJkapqalat26d7/1vvvlGWVlZatWqlVq0aKHMzExVVlYG/f0IfwAAwkS7du00Z84cFRcXa/fu3brlllt0++2364MPPpAkZWdna82aNXr55ZdVVFSkQ4cOacSIEUFfx+H1er2hHvylcAzubvYQgLDj3bjJ7CEAYSqxQc/+w0cGhuxcn8/eclmfj42N1RNPPKE77rhDbdq0UUFBge644w5J0kcffaRrr71W27dv10033VTvczLnDwCAQUQIJ/09Ho88Ho/fPqfTKafTecHPnTlzRi+//LJqamqUmpqq4uJi1dbWKi0tzXdMt27d1KFDh6DDn7Y/AAAGoZzzd7vdcrlcfpvb7T7vtd977z21aNFCTqdTEyZM0KpVq9S9e3dVVFQoMjJSLVu29Ds+Li5OFRUVQX0/Kn8AABpQbm6ucnJy/PZdqOrv2rWrSkpKVFVVpVdeeUWjR49WUVFRSMdE+AMAYBDKh/zUp8X/fZGRkercubMkKTk5Wbt27dKCBQs0cuRInT59WidOnPCr/isrKxUfHx/UmGj729CEn43Uu39cpapVO1W1aqfenl+gIb36+t6P+0FrLX9ojg6/uE0nX9ut4rxXNOLmW00cMdCwdu16VxMmTNPNN9+hrl0HatOmNy94/MaN23T//Q/qppuG6ac//S+NHJmlf/xjZyONFo3BrFv9zqWurk4ej0fJyclq2rSpCgsLfe+VlpaqvLxcqampQZ2Tyt+GDh6r1NTF87Tv80/lcEijbx2mVx99Rj/5n0zt/bRMyx9yq+WV0fr5zCwdq/pS99zyX3pp+tO6YdKdKtn/odnDB0Lu1Klv1LVrJ2VmZmjSpEcuevyuXXvUu3eysrP/WzExLfS3v63TxInT9dJLi9S9e5dGGDGsKjc3VxkZGerQoYO++uorFRQUaOvWrdqwYYNcLpfGjRunnJwcxcbGKiYmRpMnT1ZqampQi/0kwt+W1u7Y6vd6xtIFmvizu3TTtUna+2mZenf/iSYunKVdpe9Jkh4veFbZI0YruUt3wh+W1L9/ivr3T6n38dOnT/J7nZMzXoWFb2nz5rcJf4sw69n+R44c0ahRo3T48GG5XC4lJSVpw4YNuvXWs93XefPmKSIiQpmZmfJ4PEpPT9eiRYuCvg7hb3MRERH6Rb90XRnVTNv3vitJenvvvzSyf4Ze37lNJ05W687+QxQVGamte3aZPFogPNXV1amm5mu1bBlj9lAQImY93nfx4sUXfD8qKkp5eXnKy8u7rOsEHf7Hjh3TX/7yF23fvt13a0F8fLx69+6tMWPGqE2bNpc1IDSOHj/qou0L/qqoyEid/PqUhs/6lT4s3y9JuvN3OVo5/Sl98b/bVfttrU55vtHwWb/S/kPlJo8aCE+LF6/UqVNfKyNjgNlDAeolqPDftWuX0tPT1bx5c6Wlpemaa66RdHal4cKFCzVnzhxt2LBBN9xwwwXPc64HHqiuTopg/WFjKT34ia6fOEKuK1vojr7pWvbb36v/g6P1Yfl+PTb6V2rZIkaDHhqrY9VfaljvQXpp+tPqm3Of3v9kn9lDB8LKmjWblJe3XIsW/U6tWv3A7OEgREKxUC+cBRX+kydP1i9+8Qv98Y9/DPg/xuv1asKECZo8ebK2b99+wfO43W7NmjXLf+fVraVOdA0aS+23tb5K/p19e9Xrmh769fD7NPelxZo87Je6bvzPtffTMknSno9L1bdHsrJ+fo8mLpx1odMCtvL665s1Y8aTWrBgpnr3TjZ7OAghi2d/cLf6vfvuu8rOzj7nX0QOh0PZ2dkqKSm56Hlyc3NVVVXlt6ljq2CGghCLiHDI2bSpmjujJJ2dw/y+M3VnFBHK510C/+HWri1Ubu4f9NRTMzRgQHC3WQFmC6ryj4+P186dO9WtW7dzvr9z507FxcVd9DznfOABLf9G8/ux2Vq3a5vKjxxWdLMrdc8tP9OApBuVPm28PvrsgPZ9/qmenfKoHvzTEzpefULDeg/SrT/trZ89/D9mDx1oEDU1X6u8/HPf64MHD+vDD8vkckUrMTFOTz31nCorj2ru3GmSzrb6p06do2nTJqlnz+46evQLSVJUVKSio1uY8h0QWg6LFztBhf+DDz6oBx54QMXFxRo0aJAv6CsrK1VYWKjnnntOTz75ZIMMFKHTtmWslv92jhJi26jq1Ffa8/G/lT5tvDa9c3a65rbpEzRnXLbWzM5Ti2bNVfZ5uUY/kat1u7aZPHKgYbz/fqlGjcr2vXa7z946NXx4uubMmaqjR4/r8OEjvvdfemmtvv32jGbPXqDZsxf49n93PP7zWX3OP+if9F25cqXmzZun4uJinTlzRpLUpEkTJScnKycnR3feeeelDYSf9AUC8JO+wPk07E/6dv1DesjOVfr/N4TsXKES9K1+I0eO1MiRI1VbW6tjx45Jklq3bq2mTZuGfHAAACD0LvkhP02bNlVCQkIoxwIAQFiweNefJ/wBAGBk9Tl/ltgDAGAzVP4AABhwqx8AADZD2x8AAFgKlT8AAAZWr/wJfwAADKwe/rT9AQCwGSp/AAAMHBYvjQl/AAAMrN72J/wBADCwevhbvLEBAACMqPwBADCyeOVP+AMAYEDbHwAAWAqVPwAABtzqBwCAzdD2BwAAlkLlDwCAgdUrf8IfAAADq4c/bX8AAGyGyh8AAANHhLUrf8IfAAADq7f9CX8AAAwsnv3M+QMAYDdU/gAAGND2BwDAZqwe/rT9AQCwGSp/AAAMrH6rH5U/AAAGDocjZFsw3G63evXqpejoaLVt21bDhg1TaWmp3zEDBgwIuMaECROCug7hDwBAmCgqKlJWVpZ27NihN954Q7W1tRo8eLBqamr8jhs/frwOHz7s2+bOnRvUdWj7AwBgYNZ6v/Xr1/u9Xrp0qdq2bavi4mL169fPt7958+aKj4+/5OtQ+QMAYBDKtr/H41F1dbXf5vF46jWOqqoqSVJsbKzf/hdeeEGtW7dWjx49lJubq1OnTgX1/Qh/AAAakNvtlsvl8tvcbvdFP1dXV6cpU6aoT58+6tGjh2//Pffco+eff15btmxRbm6uVqxYoXvvvTeoMTm8Xq836G/SAByDu5s9BCDseDduMnsIQJhKbNCz93/xlyE718bhfwmo9J1Op5xO5wU/N3HiRK1bt05vvvmm2rVrd97jNm/erEGDBqmsrEydOnWq15iY8wcAwCCUD/mpT9AbTZo0SWvXrtW2bdsuGPySlJKSIkmEPwAAl8WkFX9er1eTJ0/WqlWrtHXrVnXs2PGinykpKZEkJSQk1Ps6hD8AAGEiKytLBQUFevXVVxUdHa2KigpJksvlUrNmzbR//34VFBTotttuU6tWrbRnzx5lZ2erX79+SkpKqvd1CH8AAAzMutUvPz9f0tkH+XzfkiVLNGbMGEVGRmrTpk2aP3++ampq1L59e2VmZmrGjBlBXYfwBwDAIMLEtv+FtG/fXkVFRZd9HW71AwDAZqj8AQAwsPpP+hL+AAAYmNX2byy0/QEAsBkqfwAADKxe+RP+AAAYEP4AANiM1Rf8MecPAIDNUPkDAGAQIWtX/oQ/AAAGEdbOftr+AADYDZU/AAAGVl/wR/gDAGBg9Vv9aPsDAGAzVP4AABhYvfIn/AEAMLB6+NP2BwDAZqj8AQAwcPCQHwAA7MXqbX/CHwAAA6uHP3P+AADYDJU/AAAGVq/8CX8AAAwsnv20/QEAsBsqfwAADGj7AwBgM1YPf9r+AADYDJU/AAAGPOEPAACboe0PAAAshcofAAADq1f+hD8AAAaEPwAANuOwePgz5w8AgM1Q+QMAYBBh7cKf8AcAwCjC4vf50/YHAMBmqPwBADBgtT8AADbDan8AANAo3G63evXqpejoaLVt21bDhg1TaWmp3zHffPONsrKy1KpVK7Vo0UKZmZmqrKwM6jqEPwAABhEOR8i2YBQVFSkrK0s7duzQG2+8odraWg0ePFg1NTW+Y7Kzs7VmzRq9/PLLKioq0qFDhzRixIigrkPbHwAAA7Pm/NevX+/3eunSpWrbtq2Ki4vVr18/VVVVafHixSooKNAtt9wiSVqyZImuvfZa7dixQzfddFO9rkPlDwBAA/J4PKqurvbbPB5PvT5bVVUlSYqNjZUkFRcXq7a2Vmlpab5junXrpg4dOmj79u31HhPhDwCAgcPhCNnmdrvlcrn8NrfbfdEx1NXVacqUKerTp4969OghSaqoqFBkZKRatmzpd2xcXJwqKirq/f1o+wMAYBDKtn9ubq5ycnL89jmdzot+LisrS++//77efPPNkI3lO2ET/t6Nm8weAhB2+qzIufhBgA29dd+LDXr+ULbFnU5nvcL++yZNmqS1a9dq27ZtateunW9/fHy8Tp8+rRMnTvhV/5WVlYqPj6/3+Wn7AwAQJrxeryZNmqRVq1Zp8+bN6tixo9/7ycnJatq0qQoLC337SktLVV5ertTU1HpfJ2wqfwAAwoVZD/nJyspSQUGBXn31VUVHR/vm8V0ul5o1ayaXy6Vx48YpJydHsbGxiomJ0eTJk5Wamlrvlf4S4Q8AQACzbvXLz8+XJA0YMMBv/5IlSzRmzBhJ0rx58xQREaHMzEx5PB6lp6dr0aJFQV2H8AcAIEx4vd6LHhMVFaW8vDzl5eVd8nUIfwAADCKs/Wh/wh8AACOHrJ3+rPYHAMBmqPwBADAwa8FfYyH8AQAwsPqcP21/AABshsofAAADqy/4I/wBADBgzh8AAJthzh8AAFgKlT8AAAZm/bBPYyH8AQAwiLD4gj/a/gAA2AyVPwAABlZf8Ef4AwBgYPU5f9r+AADYDJU/AAAGVl/wR/gDAGBg9Tl/2v4AANgMlT8AAAZWX/BH+AMAYMAP+wAAYDNWnxO3+vcDAAAGVP4AABgw5w8AgM1Yfc6ftj8AADZD5Q8AgIHVH/JD+AMAYOCw+ON9afsDAGAzVP4AABjQ9gcAwGZY7Q8AACyFyh8AAAOrL/gj/AEAMGDOHwAAm2HOHwAAWAqVPwAABvywDwAANmP1trjVvx8AADAg/AEAMIhwOEK2BWPbtm0aOnSoEhMT5XA4tHr1ar/3x4wZI4fD4bcNGTIk6O9H2x8AAAOz5vxramrUs2dPjR07ViNGjDjnMUOGDNGSJUt8r51OZ9DXIfwBAAgTGRkZysjIuOAxTqdT8fHxl3Ud2v4AABhEhHDzeDyqrq722zwezyWPbevWrWrbtq26du2qiRMn6vjx45f0/QAAwPcY59UvZ3O73XK5XH6b2+2+pHENGTJEy5cvV2Fhof7whz+oqKhIGRkZOnPmTFDnoe0PAEADys3NVU5Ojt++S5mnl6S77rrL988//vGPlZSUpE6dOmnr1q0aNGhQvc9D+AMAYBDKx/s6nc5LDvuLufrqq9W6dWuVlZUR/gAAXI7/lOf7HTx4UMePH1dCQkJQnyP8AQAwMOtWv5MnT6qsrMz3+sCBAyopKVFsbKxiY2M1a9YsZWZmKj4+Xvv379dDDz2kzp07Kz09PajrEP4AAISJ3bt3a+DAgb7X360VGD16tPLz87Vnzx4tW7ZMJ06cUGJiogYPHqzHHnss6GkFwh8AAIMIkxr/AwYMkNfrPe/7GzZsCMl1CH8AAAws/qN+3OcPAIDdUPkDAGAQylv9whHhDwCAgeM/5ma/S0PbHwAAm6HyBwDAwOJdf8IfAAAjs271ayy0/QEAsBkqfwAADMx6vG9jIfwBADCwePYT/gAAGDHnDwAALIXKHwAAA+b8AQCwGau3xa3+/QAAgAGVPwAABrT9AQCwGauHP21/AABshsofAAADq1fGhD8AAAa0/QEAgKVQ+QMAYOCw+ON9CX8AAAwirJ39hD8AAEZWr/yZ8wcAwGao/AEAMIiw+Gp/wh8AAAOLZz9tfwAA7IbKHwAAA6sv+CP8AQAwsPqcP21/AABshsofAAADa9f9hL+t7Nr1rhYvXqn33/+3jh49rry8x5SWdvN5j9+4cZv++tfX9OGHZTp9ulZduvxIkyaNVt++NzbiqIHGc1+P29W//Y26ypUoz5nTeu/ov5X/ToHKqw/7HXdd6y76fz8Zqe6tO6uurk77vvxU2YW/1+kztSaNHKFG2x+WcerUN+ratZNmzvx1vY7ftWuPevdO1p/+NEd/+9uzSkm5XhMnTtfevfsaeKSAOa5ve63+VrpRD6x7WFM2Pa4rHE00b9A0RV3h9B1zXesuenpQrnYe2qPxf5+h/143Xf9bukFer9fEkQPBofK3kf79U9S/f0q9j58+fZLf65yc8SosfEubN7+t7t27hHp4gOl+s3mO3+vH387X63c+p66xHfXukY8kSb++YZRe+Wi9nv/gNd9xxs4A/vNZ/Sd9CX/UW11dnWpqvlbLljFmDwVoFFdGNpckVZ8+KUlqGRWj69p00cYDb+qP6bP1w+i2+rT6kP70r5Xac7TUzKEixKwd/bT9EYTFi1fq1KmvlZExwOyhAA3OIYd+fcNovXvkIx04cVCS9MMWbSVJY3veodfKCpVTOEf//uITLbh1htpFx5s5XIRYhMMRsi0chTz8P/vsM40dO/aCx3g8HlVXV/ttHo8n1ENBCK1Zs0l5ecs1f/5MtWr1A7OHAzS439w4Vle3bK+Z/1jo2+dwnP1P5qv/LtTf9xdp35efaOHu5SqvPqSfdR5g0kiB4IU8/L/44gstW7bsgse43W65XC6/ze1+JtRDQYi8/vpmzZjxpObPf0S9eyebPRygweX0ul+92/1Uk9+YraOnvvDtP/71l5KkA1UH/Y7/tOqQ4q5s3ahjRMNyhPB/wdi2bZuGDh2qxMREORwOrV692u99r9erRx55RAkJCWrWrJnS0tK0b1/wi7CDnvN/7bXXLvj+xx9/fNFz5ObmKicnx2+f03k82KGgEaxdW6hp0+bq6acf1oABqWYPB2hwOb3uV78OvTRp42wdPnnU773DJ4/q6KkvdFVMot/+9jHx2vH5u405TDQws7r1NTU16tmzp8aOHasRI0YEvD937lwtXLhQy5YtU8eOHfXwww8rPT1de/fuVVRUVL2vE3T4Dxs2TA6H44K3tVxslaTT6ZTT6TTsPRnsUBCkmpqvVV7+ue/1wYOH9eGHZXK5opWYGKennnpOlZVHNXfuNElnW/1Tp87RtGmT1LNndx09erYCioqKVHR0C1O+A9CQfnPjWN3asY+mbnlSp2q/VmyUS5J0svaU7x7+gg/WaFzPX2jfl59q35ef6Lar++uqmB9qRtF8E0cOq8jIyFBGRsY53/N6vZo/f75mzJih22+/XZK0fPlyxcXFafXq1brrrrvqfZ2gwz8hIUGLFi3yXdiopKREycm0hsPR+++XatSobN9rt3uRJGn48HTNmTNVR48e1+HDR3zvv/TSWn377RnNnr1As2cv8O3/7njAakZ0HSxJykuf6bf/8bfy9fePiyRJL320TpFNmupXN4xSjPNKlX1RrimbHtfnJysbfbxoOKH8YR+PxxOwru3cRfCFHThwQBUVFUpLS/Ptc7lcSklJ0fbt2xs2/JOTk1VcXHze8L9YVwDmSUm5XqWlW877vjHQV6yY38AjAsJLnxX1+4/n8x+85nefP6wnlOHvdrs1a9Ysv30zZ87Uo48+GtR5KioqJElxcXF+++Pi4nzv1VfQ4f/b3/5WNTU1532/c+fO2rLl/AEDAICdnHudW3BVf6gFHf59+/a94PtXXnml+vfvf8kDAgDAdCFc8HcpLf5ziY8/+yyJyspKJSQk+PZXVlbq+uuvD+pcPOQHAAADs271u5COHTsqPj5ehYWFvn3V1dX65z//qdTU4O7G4vG+AACEiZMnT6qsrMz3+sCBAyopKVFsbKw6dOigKVOm6He/+526dOniu9UvMTFRw4YNC+o6hD8AAAZm/bDP7t27NXDgQN/r79YKjB49WkuXLtVDDz2kmpoaPfDAAzpx4oRuvvlmrV+/Pqh7/CXJ4Q2bpfmHzB4AEHb6rMi5+EGADb1134sNev5PT64M2bmuajEyZOcKFSp/AAAMQjlXH45Y8AcAgM1Q+QMAYGDWnH9jIfwBADCwdvTT9gcAwHao/AEAMLD6gj/CHwAAA6vP+dP2BwDAZqj8AQAwsHbdT/gDABCAtj8AALAUKn8AAAxY7Q8AgM0Q/gAA2IzFp/yZ8wcAwG6o/AEAMKDtDwCAzVg9/Gn7AwBgM1T+AAAYWH3BH+EPAEAAa6c/bX8AAGyGyh8AAAOrP9uf8AcAwMDa0U/bHwAA26HyBwDAwOr3+RP+AAAYMOcPAIDNWDv6mfMHAMB2qPwBADBgzh8AAJux+pw/bX8AAGyGyh8AAAPa/gAA2IzFu/60/QEAsBsqfwAADGj7AwBgO9YOf9r+AADYDJU/AAABrF0bE/4AABhYfc7f2n/aAABwSRwh3Orv0UcflcPh8Nu6desWkm/0fVT+AACEkeuuu06bNm3yvb7iitBHNeEPAEAA8xrjV1xxheLj4xv0GrT9AQAwcjhCtnk8HlVXV/ttHo/nvJfet2+fEhMTdfXVV+uXv/ylysvLQ/71CH8AABqQ2+2Wy+Xy29xu9zmPTUlJ0dKlS7V+/Xrl5+frwIED6tu3r7766quQjsnh9Xq9IT3jJTtk9gCAsNNnRY7ZQwDC0lv3vdig5z9d94+Qnctbe2NApe90OuV0Oi/62RMnTuiqq67S008/rXHjxoVsTMz5AwAQIHSN8foG/bm0bNlS11xzjcrKykI2Hom2PwAAYevkyZPav3+/EhISQnpewh8AgADm3Of/4IMPqqioSJ988onefvttDR8+XE2aNNHdd98dkm/1Hdr+AAAEMKc2PnjwoO6++24dP35cbdq00c0336wdO3aoTZs2Ib0O4Q8AQJh48cWGXcj4HcIfAAADqz/bn/AHACAA4Q8AgM1Yez28tb8dAAAIQOUPAEAA2v4AANiKw+KNcWt/OwAAEIDKHwCAALT9AQCwF4e1w5+2PwAANkPlDwBAAGvXxoQ/AAAGVn+8r7X/tAEAAAGo/AEACGDtyp/wBwAggLUb44Q/AAABrF35W/tPGwAAEIDKHwAAA6s/25/wBwAgAG1/AABgIVT+AAAEsHblT/gDABDA2o1xa387AAAQgMofAAADh8V/0pfwBwAggLXDn7Y/AAA2Q+UPAEAAa9fGhD8AAAGs3fYn/AEAMLD6432t/e0AAEAAKn8AAAJYu+3v8Hq9XrMHgfDh8XjkdruVm5srp9Np9nCAsMC/F7Aawh9+qqur5XK5VFVVpZiYGLOHA4QF/r2A1TDnDwCAzRD+AADYDOEPAIDNEP7w43Q6NXPmTBY1Ad/DvxewGhb8AQBgM1T+AADYDOEPAIDNEP4AANgM4Q8AgM0Q/vDJy8vTj370I0VFRSklJUU7d+40e0iAqbZt26ahQ4cqMTFRDodDq1evNntIQEgQ/pAkrVy5Ujk5OZo5c6beeecd9ezZU+np6Tpy5IjZQwNMU1NTo549eyovL8/soQAhxa1+kCSlpKSoV69eeuaZZyRJdXV1at++vSZPnqypU6eaPDrAfA6HQ6tWrdKwYcPMHgpw2aj8odOnT6u4uFhpaWm+fREREUpLS9P27dtNHBkAoCEQ/tCxY8d05swZxcXF+e2Pi4tTRUWFSaMCADQUwh8AAJsh/KHWrVurSZMmqqys9NtfWVmp+Ph4k0YFAGgohD8UGRmp5ORkFRYW+vbV1dWpsLBQqampJo4MANAQrjB7AAgPOTk5Gj16tG644QbdeOONmj9/vmpqanT//febPTTANCdPnlRZWZnv9YEDB1RSUqLY2Fh16NDBxJEBl4db/eDzzDPP6IknnlBFRYWuv/56LVy4UCkpKWYPCzDN1q1bNXDgwID9o0eP1tKlSxt/QECIEP4AANgMc/4AANgM4Q8AgM0Q/gAA2AzhDwCAzRD+AADYDOEPAIDNEP4AANgM4Q8AgM0Q/gAA2AzhDwCAzRD+AADYDOEPAIDN/B8njSJCOMz/ZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pred_2 = model_2.predict(X_test_transf)\n",
    "pred_2 = (model_2.predict_proba(X_test_transf)[:,1] >= 0.4).astype(bool)\n",
    "\n",
    "conf_mat_2 = confusion_matrix(y_test, pred_2)/1000\n",
    "\n",
    "print(classification_report(y_test, pred_2))\n",
    "\n",
    "sns.heatmap(conf_mat_2, annot=True,  cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "489",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 489",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m y_drop \u001b[38;5;241m=\u001b[39m droped[(droped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanceled\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m (droped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLive\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanceled\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLive\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m      6\u001b[0m X_drop_pre \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_drop)\n\u001b[1;32m----> 7\u001b[0m X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnames_vectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_drop_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal__name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGLOVE_LIB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m X_drop_pre \u001b[38;5;241m=\u001b[39m X_drop_pre\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal__name\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(clasters\u001b[38;5;241m.\u001b[39mpredict(X_drop_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()),  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 68\u001b[0m, in \u001b[0;36mnames_vectorizer\u001b[1;34m(df, colname, model)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m itr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new_col\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     67\u001b[0m     vec_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 68\u001b[0m     new_col[itr] \u001b[38;5;241m=\u001b[39m whole_name_vectorizer(\u001b[43mnew_col\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m]\u001b[49m, model)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(new_col)\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32md:\\DSMLAI\\ML_GroupProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 489"
     ]
    }
   ],
   "source": [
    "droped = pd.read_csv('./data/droped_states.csv')\n",
    "droped['state']\n",
    "X_drop = droped[(droped['state'] == 'Canceled') | (droped['state'] == 'Live')].drop('state', axis=1)\n",
    "y_drop = droped[(droped['state'] == 'Canceled') | (droped['state'] == 'Live')]['state'].map({'Canceled':0, 'Live':1})\n",
    "\n",
    "X_drop_pre = preprocessor.transform(X_drop)\n",
    "X_drop_pre['vec_name'] = names_vectorizer(df=X_drop_pre, colname='original__name', model=GLOVE_LIB)\n",
    "X_drop_pre = X_drop_pre.drop('original__name', axis=1)\n",
    "X_drop_pre['name_cluster'] = pd.Series(clasters.predict(X_drop_pre['vec_name'].values.tolist()),  name='name_cluster')\n",
    "X_drop_pre = X_drop_pre.drop('vec_name', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_droped_2 = model_2.predict(X_drop_trans)\n",
    "#pred_droped_2 = (model_2.predict_proba(X_drop_trans)[:,1] >= 0.4).astype(bool)\n",
    "\n",
    "conf_mat_drop = confusion_matrix(y_drop, pred_droped_2)/1000\n",
    "\n",
    "print(classification_report(y_drop, pred_droped_2))\n",
    "\n",
    "sns.heatmap(conf_mat_drop, annot=True,  cmap='YlGn')\n",
    "\n",
    "TEST_DATA_LINE = pd.DataFrame({'name': ['LETS TRY SOMETHING UNUSUAL'],\n",
    "                'category': ['Music'],\n",
    "                'subcategory': ['MADNESS'],\n",
    "                'country': ['Germany'],\n",
    "                'launched': ['2012-06-16 23:05:26'],\n",
    "                'deadline': ['2032-06-16'],\n",
    "                'goal': [100000],\n",
    "                'pledged': [2],\n",
    "                'backers':[1]}\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
